{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print torch.__version__\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array(pd.read_csv('../../data/input_formated/v0/x_train.csv').iloc[:, 1:],dtype = np.float32)\n",
    "y_train = np.array(pd.read_csv('../../data/input_formated/v0/y_train.csv').iloc[:, 1:],dtype = np.float32).reshape((-1, 1))\n",
    "x_test = np.array(pd.read_csv('../../data/input_formated/v0/x_test.csv').iloc[:, 1:],dtype = np.float32)\n",
    "y_test = np.array(pd.read_csv('../../data/input_formated/v0/y_test.csv').iloc[:, 1:],dtype = np.float32).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Network Model (1 hidden layer)\n",
    "class ANN_1hidden(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ANN_1hidden, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.activate = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.activate(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(x_data, y_data, learning_rate, num_epochs, check_point, model_save = None):\n",
    "\tn = int(0.8 * len(x_data))\n",
    "\tx_train, y_train = x_data[:n,:], y_data[:n, :]\n",
    "\tx_val, y_val = x_data[n:, :], y_data[n:, :]\n",
    "\t\n",
    "\tmodel = ANN_1hidden(x_train.shape[1], 10, y_train.shape[1])\n",
    "\tcriterion = nn.MSELoss()\n",
    "\toptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\ttrain_loss_list, val_loss_list = [], []\n",
    "\n",
    "\t#early stopping\n",
    "\tmax_patience = 100\n",
    "\tpatience = max_patience\n",
    "\tbest_val = None\n",
    "\t\n",
    "\t# Train the Model \n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\t# Convert numpy array to torch Variable\n",
    "\t\tinputs = Variable(torch.from_numpy(x_train))\n",
    "\t\ttargets = Variable(torch.from_numpy(y_train), requires_grad = False)\n",
    "\n",
    "\t\t# Forward + Backward + Optimize\n",
    "\t\toptimizer.zero_grad()  \n",
    "\t\toutputs = model(inputs)\n",
    "\t\t\n",
    "\t\ttrain_loss = criterion(outputs, targets).sum()\n",
    "\t\ttrain_loss_list.append(train_loss.data[0])\n",
    "\t\t\n",
    "\t\t#validate\n",
    "\t\tinputs = Variable(torch.from_numpy(x_val))\n",
    "\t\ttargets = Variable(torch.from_numpy(y_val), requires_grad = False)\n",
    "\t\toutputs = model(inputs)   \n",
    "\t\tval_loss = criterion(outputs, targets).sum().data[0]\n",
    "\t\tval_loss_list.append(val_loss)\n",
    "\t\t\n",
    "\t\t#optimize\n",
    "\t\ttrain_loss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\tif (epoch == 0) or ((epoch+1) % check_point == 0) or (epoch == num_epochs-1):\n",
    "\t\t\tprint ('Epoch [%d/%d], Training Loss: %.4f, Validating Loss: %.4f' \n",
    "\t\t\t\t   %(epoch+1, num_epochs, train_loss.data[0], val_loss))\n",
    "\t\t\tif model_save is not None:            \n",
    "\t\t\t\ttorch.save(model, '%s/%d.pth' % (model_save, epoch+1))\n",
    "\n",
    "\t\tif (best_val is None) or ((best_val is not None) and (val_loss < best_val)) :\n",
    "\t\t\tbest_val = val_loss\n",
    "\t\t\tpatience =max_patience\n",
    "\t\telse:\n",
    "\t\t\tpatience -= 1\n",
    "\t\tif patience == 0:\n",
    "\t\t\tprint 'Early stopping at %d' % epoch\n",
    "\t\t\tbreak\n",
    "\t\t\n",
    "\n",
    "\t# Plot the graph\n",
    "\tprint 'Plot graph from epoch 10th'\n",
    "\tplt.plot(range(len(train_loss_list))[10:], train_loss_list[10:], label='train')\n",
    "\tplt.plot(range(len(train_loss_list))[10:], val_loss_list[10:], label = 'validate')\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Training Loss: 10.1984, Validating Loss: 10.0916\n",
      "Epoch [100/1000], Training Loss: 0.4118, Validating Loss: 0.4166\n",
      "Epoch [200/1000], Training Loss: 0.3933, Validating Loss: 0.3883\n",
      "Epoch [300/1000], Training Loss: 0.3898, Validating Loss: 0.3845\n",
      "Epoch [400/1000], Training Loss: 0.3881, Validating Loss: 0.3832\n",
      "Epoch [500/1000], Training Loss: 0.3870, Validating Loss: 0.3827\n",
      "Epoch [600/1000], Training Loss: 0.3864, Validating Loss: 0.3825\n",
      "Epoch [700/1000], Training Loss: 0.3860, Validating Loss: 0.3824\n",
      "Epoch [800/1000], Training Loss: 0.3855, Validating Loss: 0.3823\n",
      "Epoch [900/1000], Training Loss: 0.3850, Validating Loss: 0.3822\n",
      "Epoch [1000/1000], Training Loss: 0.3843, Validating Loss: 0.3819\n",
      "Plot graph from epoch 10th\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wGf6mbCnYJ/qQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb6df818610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train(x_train, y_train, learning_rate = 0.01, num_epochs= 1000, check_point = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(y, y_hat):\n",
    "    \"\"\"Compute root mean squared error\"\"\"\n",
    "    return torch.sqrt(torch.mean((y - y_hat).pow(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANN_1hidden (\n",
       "  (fc1): Linear (18 -> 10)\n",
       "  (activate): Sigmoid ()\n",
       "  (fc2): Linear (10 -> 1)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(316, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.6091\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array(pd.read_csv('../../data/input_formated/v0/x_test.csv').iloc[:, 1:], dtype=np.float32)\n",
    "y_test = np.array(pd.read_csv('../../data/input_formated/v0/y_test.csv').iloc[:, 1:], dtype=np.float32)\n",
    "print x_test.shape\n",
    "inputs = Variable(torch.from_numpy(x_test))\n",
    "predict = model(Variable(torch.from_numpy(x_test)))\n",
    "targets = Variable(torch.from_numpy(np.array(y_test, dtype=np.float32)))\n",
    "rmse(predict, targets).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.5441\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.loadtxt('../../data/input_formated/nouser/x_test.csv')\n",
    "y_test = np.loadtxt('../../data/input_formated/nouser/y_test.csv')\n",
    "x_test = np.array(x_test, dtype = np.float32)\n",
    "y_test = np.array(y_test, dtype = np.float32)\n",
    "inputs = Variable(torch.from_numpy(x_test))\n",
    "predict = model(Variable(torch.from_numpy(x_test)))\n",
    "targets = Variable(torch.from_numpy(np.array(y_test, dtype=np.float32)))\n",
    "rmse(predict, targets).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
